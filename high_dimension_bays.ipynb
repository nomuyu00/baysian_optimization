{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T10:10:53.882518Z",
     "start_time": "2024-08-29T10:10:53.878717Z"
    }
   },
   "source": [
    "from IPython.utils import io\n",
    "import os\n",
    "import subprocess\n",
    "import tqdm.notebook\n",
    "\n",
    "TQDM_BAR_FORMAT = '{l_bar}{bar}| {n_fmt}/{total_fmt} [elapsed: {elapsed} remaining: {remaining}]'\n"
   ],
   "outputs": [],
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5b0mNZdUCUhZ",
    "ExecuteTime": {
     "end_time": "2024-08-29T10:10:53.948189Z",
     "start_time": "2024-08-29T10:10:53.943736Z"
    }
   },
   "source": [
    "import torch\n",
    "from botorch import fit_gpytorch_model\n",
    "from botorch.acquisition import UpperConfidenceBound\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.optim import optimize_acqf\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from gpytorch.kernels import RBFKernel, ScaleKernel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import softmax\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from botorch.models import SaasFullyBayesianSingleTaskGP\n",
    "from gpytorch.kernels import MaternKernel, ScaleKernel\n",
    "from gpytorch import constraints"
   ],
   "outputs": [],
   "execution_count": 77
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6vSA03y-DlJ"
   },
   "source": [
    "# 目的関数の用意 (Rosenbrock関数)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bXL2EF3t-Jlj",
    "ExecuteTime": {
     "end_time": "2024-08-29T10:10:53.951137Z",
     "start_time": "2024-08-29T10:10:53.948189Z"
    }
   },
   "source": [
    "def styblinski_tang(x):\n",
    "    indices = [2, 3, 5, 7, 9]\n",
    "    x_selected = x[..., indices]\n",
    "    return 0.5 * torch.sum(x_selected ** 4 - 16 * x_selected ** 2 + 5 * x_selected, dim=-1)"
   ],
   "outputs": [],
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "d3CnViCV-O8t",
    "ExecuteTime": {
     "end_time": "2024-08-29T10:10:53.957842Z",
     "start_time": "2024-08-29T10:10:53.956140Z"
    }
   },
   "source": [
    "# styblinski_tang関数の最適解\n",
    "global_optimum = -39.16599 * 25"
   ],
   "outputs": [],
   "execution_count": 79
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8w-P5Vpg-s1_"
   },
   "source": [
    "# 初期点の生成関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XMsy_wo-yTR"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "i2mpt0XN-ys4",
    "ExecuteTime": {
     "end_time": "2024-08-29T10:10:53.967504Z",
     "start_time": "2024-08-29T10:10:53.964845Z"
    }
   },
   "source": [
    "def generate_initial_points(n_initial, dim, bounds):\n",
    "    return torch.rand(n_initial, dim) * (bounds[1] - bounds[0]) + bounds[0]"
   ],
   "outputs": [],
   "execution_count": 80
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-U8hGE6G-7jh"
   },
   "source": [
    "# モデル作成関数\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "k05lLlt9-6fL",
    "ExecuteTime": {
     "end_time": "2024-08-29T10:10:53.971377Z",
     "start_time": "2024-08-29T10:10:53.968508Z"
    }
   },
   "source": [
    "def create_model(train_X, train_Y):\n",
    "    kernel = ScaleKernel(RBFKernel(ard_num_dims=train_X.shape[-1], noise_constraint=1e-5))\n",
    "    model = SingleTaskGP(train_X, train_Y, covar_module=kernel)\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 81
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCc5R9W7_BmY"
   },
   "source": [
    "# ドロップアウトベイズクラス"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bAATR5uq_Jb6",
    "ExecuteTime": {
     "end_time": "2024-08-29T10:10:53.977922Z",
     "start_time": "2024-08-29T10:10:53.971377Z"
    }
   },
   "source": [
    "class DropoutMixBO:\n",
    "    def __init__(self, dim, active_dim, bounds, n_initial,obj_function, dropout_prob=0.1):\n",
    "        self.dim = dim\n",
    "        self.active_dim = active_dim\n",
    "        self.bounds = bounds\n",
    "        self.obj_function = obj_function\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.X = generate_initial_points(n_initial, dim, bounds)\n",
    "        self.Y = self.obj_function(self.X)\n",
    "        self.best_f = self.Y.min().item()\n",
    "        self.best_x = self.X[self.Y.argmin()]\n",
    "        self.eval_history = [self.best_f] * n_initial\n",
    "\n",
    "    def optimize(self, n_iter):\n",
    "        for _ in range(n_iter):\n",
    "            # 全次元からランダムにactive_dim個選ぶ\n",
    "            active_dims = np.random.choice(self.dim, self.active_dim, replace=False)\n",
    "\n",
    "            train_X = self.X[:, active_dims]\n",
    "            train_Y = self.Y.unsqueeze(-1)\n",
    "            model = create_model(train_X, train_Y)\n",
    "            mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "            fit_gpytorch_model(mll)\n",
    "\n",
    "            UCB = UpperConfidenceBound(model, beta=0.1)\n",
    "            bounds_active = torch.stack([self.bounds[0][active_dims], self.bounds[1][active_dims]])\n",
    "            candidate, _ = optimize_acqf(\n",
    "                UCB, bounds=bounds_active, q=1, num_restarts=5, raw_samples=20,\n",
    "            )\n",
    "\n",
    "            x_new = torch.zeros(self.dim)\n",
    "            if np.random.random() < self.dropout_prob:\n",
    "                x_new[active_dims] = candidate.squeeze()\n",
    "                inactive_dims = np.setdiff1d(range(self.dim), active_dims)\n",
    "                x_new[inactive_dims] = (torch.rand(len(inactive_dims))\n",
    "                                        * (self.bounds[1][inactive_dims] - self.bounds[0][inactive_dims])\n",
    "                                        + self.bounds[0][inactive_dims])\n",
    "            else:\n",
    "                x_new[active_dims] = candidate.squeeze()\n",
    "                x_new[np.setdiff1d(range(self.dim), active_dims)] = self.best_x[\n",
    "                    np.setdiff1d(range(self.dim), active_dims)]\n",
    "\n",
    "            y_new = self.obj_function(x_new.unsqueeze(0))\n",
    "\n",
    "            self.X = torch.cat([self.X, x_new.unsqueeze(0)])\n",
    "            self.Y = torch.cat([self.Y, y_new])\n",
    "\n",
    "            if y_new < self.best_f:\n",
    "                self.best_f = y_new.item()\n",
    "                self.best_x = x_new\n",
    "\n",
    "            self.eval_history.append(self.best_f)\n",
    "\n",
    "        return self.best_x, self.best_f"
   ],
   "outputs": [],
   "execution_count": 82
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REMBO"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T10:10:53.983150Z",
     "start_time": "2024-08-29T10:10:53.977922Z"
    }
   },
   "source": [
    "class REMBO:\n",
    "    def __init__(self, high_dim, low_dim, bounds, n_initial, obj_function):\n",
    "        assert high_dim >= low_dim, \"high_dim must be greater than or equal to low_dim\"\n",
    "\n",
    "        self.high_dim = high_dim\n",
    "        self.low_dim = low_dim\n",
    "        self.bounds = bounds\n",
    "        self.obj_function = obj_function\n",
    "        \n",
    "        # すべてのテンソルをdouble型に変更\n",
    "        self.A = torch.randn(high_dim, low_dim, dtype=torch.double)\n",
    "        \n",
    "        self.X_low = (torch.randn(n_initial, low_dim, dtype=torch.double) * 2 - 1)\n",
    "        \n",
    "        self.X_high = torch.clamp(self.X_low @ self.A.t(), bounds[0], bounds[1])\n",
    "        assert self.X_high.shape == (n_initial, high_dim), f\"Expected shape {(n_initial, high_dim)}, but got {self.X_high.shape}\"\n",
    "        \n",
    "        self.Y = self.obj_function(self.X_high)\n",
    "        \n",
    "        self.best_f = self.Y.min().item()\n",
    "        self.best_x = self.X_high[self.Y.argmin()]\n",
    "        self.eval_history = [self.best_f] * n_initial\n",
    "\n",
    "    def optimize(self, n_iter):\n",
    "        for _ in range(n_iter):\n",
    "            train_X_low = self.X_low\n",
    "            train_Y = self.Y.unsqueeze(-1)\n",
    "            model = SingleTaskGP(train_X_low, train_Y)\n",
    "            mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "            fit_gpytorch_model(mll)\n",
    "\n",
    "            UCB = UpperConfidenceBound(model, beta=0.1)\n",
    "            \n",
    "            bounds_low = torch.stack([torch.ones(self.low_dim, dtype=torch.double) * -1, torch.ones(self.low_dim, dtype=torch.double)])\n",
    "            candidate_low, _ = optimize_acqf(\n",
    "                UCB, bounds=bounds_low, q=1, num_restarts=5, raw_samples=20,\n",
    "            )\n",
    "\n",
    "            x_high = torch.clamp(candidate_low @ self.A.t(), self.bounds[0], self.bounds[1])\n",
    "            y_new = self.obj_function(x_high)\n",
    "\n",
    "            self.X_low = torch.cat([self.X_low, candidate_low])\n",
    "            self.X_high = torch.cat([self.X_high, x_high])\n",
    "            self.Y = torch.cat([self.Y, y_new])\n",
    "\n",
    "            if y_new < self.best_f:\n",
    "                self.best_f = y_new.item()\n",
    "                self.best_x = x_high.squeeze()\n",
    "\n",
    "            self.eval_history.append(self.best_f)\n",
    "\n",
    "        return self.best_x, self.best_f"
   ],
   "outputs": [],
   "execution_count": 83
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BC-UCBアルゴリズムを取り入れたDropoutMixBO_BCUCBクラス"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T10:10:54.012843Z",
     "start_time": "2024-08-29T10:10:54.000153Z"
    }
   },
   "source": [
    "class DropoutMixBO_BC_UCB:\n",
    "    def __init__(self, dim, active_dim, bounds, n_initial, obj_function, dropout_prob=0.1, epsilon=0.05,\n",
    "                 temperature=1e-3, reset_interval=1000, learning_rate=0.005, initial_beta=0.1, annealing_rate=1000):\n",
    "        self.dim = dim\n",
    "        self.active_dim = active_dim\n",
    "        self.bounds = bounds\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.obj_function = obj_function\n",
    "        self.epsilon = epsilon\n",
    "        self.temperature = temperature\n",
    "        self.reset_interval = reset_interval\n",
    "        self.iteration = 0\n",
    "        self.learning_rate = learning_rate\n",
    "        self.initial_beta = initial_beta\n",
    "        self.annealing_rate = annealing_rate\n",
    "\n",
    "        initial_X = self.generate_initial_points(n_initial, dim, bounds)\n",
    "        initial_Y = obj_function(initial_X)\n",
    "\n",
    "        self.X = torch.tensor(initial_X, dtype=torch.double)\n",
    "        self.Y = torch.tensor(initial_Y, dtype=torch.double)\n",
    "\n",
    "        self.best_f = self.Y.min().item()\n",
    "        self.best_x = self.X[self.Y.argmin()]\n",
    "        self.eval_history = [self.best_f] * n_initial\n",
    "        self.improvement_history = []\n",
    "\n",
    "        self.arm_rewards = np.zeros(dim)\n",
    "        self.arm_counts = np.zeros(dim)\n",
    "        self.total_pulls = 0\n",
    "        self.dim_importance = np.ones(dim) / dim\n",
    "        self.dim_sensitivity = np.zeros(dim)\n",
    "\n",
    "        self.arm_selection_history = []\n",
    "        self.sigma_history = []\n",
    "\n",
    "    def generate_initial_points(self, n_initial, dim, bounds):\n",
    "        return torch.rand(n_initial, dim) * (bounds[1] - bounds[0]) + bounds[0]\n",
    "\n",
    "    def select_active_dims(self):\n",
    "        self.iteration += 1\n",
    "\n",
    "        if np.random.random() < max(self.epsilon * np.exp(-self.iteration / 10000), 0.01):\n",
    "            selected_arms = np.random.choice(self.dim, self.active_dim, replace=False)\n",
    "        else:\n",
    "            ucb_scores = self.calculate_ucb_scores()\n",
    "            \n",
    "            # UCBスコアの正規化\n",
    "            ucb_scores = np.clip(ucb_scores, -10, 10)  # 極端な値をクリップ\n",
    "            ucb_scores = ucb_scores - np.min(ucb_scores)  # 最小値を0にシフト\n",
    "            max_score = np.max(ucb_scores)\n",
    "            if max_score > 0:\n",
    "                ucb_scores = ucb_scores / max_score  # 最大値を1に正規化\n",
    "            \n",
    "            # ソフトマックスの適用\n",
    "            probabilities = softmax(ucb_scores / self.temperature)\n",
    "            \n",
    "            # NaNやinfの処理\n",
    "            probabilities = np.nan_to_num(probabilities, nan=1.0/self.dim, posinf=1.0, neginf=0.0)\n",
    "            \n",
    "            # 確率の正規化\n",
    "            probabilities = np.clip(probabilities, 1e-10, 1)\n",
    "            probabilities /= probabilities.sum()\n",
    "            \n",
    "            selected_arms = np.random.choice(self.dim, self.active_dim, replace=False, p=probabilities)\n",
    "\n",
    "        arm_selection = np.zeros(self.dim)\n",
    "        arm_selection[selected_arms] = 1\n",
    "        self.arm_selection_history.append(arm_selection)\n",
    "\n",
    "        if self.iteration % self.reset_interval == 0:\n",
    "            self.arm_rewards *= 0.5\n",
    "            self.arm_counts *= 0.5\n",
    "\n",
    "        return selected_arms\n",
    "\n",
    "    def calculate_ucb_scores(self):\n",
    "        exploration_term = np.sqrt(2 * np.log(self.total_pulls + 1) / (self.arm_counts + 1e-5))\n",
    "        exploitation_term = self.arm_rewards / (self.arm_counts + 1e-5)\n",
    "        \n",
    "        # アニーリングスケジュールの導入\n",
    "        beta = self.initial_beta * np.exp(-self.iteration / self.annealing_rate)\n",
    "        \n",
    "        ucb_scores = exploitation_term + beta * exploration_term\n",
    "        return ucb_scores * self.dim_importance\n",
    "\n",
    "    def calculate_dimension_sensitivity(self):\n",
    "        sensitivities = np.zeros(self.dim)\n",
    "        for i in range(self.dim):\n",
    "            sorted_indices = np.argsort(self.X[:, i])\n",
    "            sorted_y = self.Y[sorted_indices]\n",
    "            diffs = np.diff(sorted_y) / np.diff(self.X[sorted_indices, i])\n",
    "            sensitivities[i] = np.mean(np.abs(diffs))\n",
    "        \n",
    "        total_sensitivity = np.sum(sensitivities) + 1e-10\n",
    "        self.dim_sensitivity = sensitivities / total_sensitivity\n",
    "        \n",
    "        # 指数移動平均を使用して感度を更新\n",
    "        alpha = 0.1  # 平滑化係数\n",
    "        self.dim_sensitivity = alpha * self.dim_sensitivity + (1 - alpha) * self.dim_sensitivity\n",
    "\n",
    "    def update_bandit(self, selected_dims, y_new):\n",
    "        improvement = max(0, self.best_f - y_new)\n",
    "        relative_improvement = improvement / (abs(self.best_f) + 1e-8)\n",
    "        \n",
    "        self.total_pulls += 1\n",
    "        for dim in selected_dims:\n",
    "            self.arm_counts[dim] += 1\n",
    "            arm_contribution = relative_improvement * self.dim_sensitivity[dim] / (sum(self.dim_sensitivity[selected_dims]) + 1e-10)\n",
    "            self.arm_rewards[dim] += arm_contribution\n",
    "        \n",
    "        importance_update = self.dim_sensitivity / (np.sum(self.dim_sensitivity) + 1e-10)\n",
    "        self.dim_importance = (1 - self.learning_rate) * self.dim_importance + self.learning_rate * importance_update\n",
    "        self.dim_importance = np.clip(self.dim_importance, 1e-10, 1)\n",
    "        self.dim_importance /= np.sum(self.dim_importance)\n",
    "    \n",
    "        # 報酬の正規化を追加\n",
    "        self.arm_rewards = (self.arm_rewards - np.mean(self.arm_rewards)) / (np.std(self.arm_rewards) + 1e-8)\n",
    "\n",
    "    def create_model(self, train_X, train_Y):\n",
    "        model = SingleTaskGP(train_X, train_Y)\n",
    "        return model\n",
    "\n",
    "    def optimize(self, n_iter):\n",
    "        for _ in range(n_iter):\n",
    "            active_dims = self.select_active_dims()\n",
    "\n",
    "            train_X = self.X[:, active_dims]\n",
    "            train_Y = self.Y.unsqueeze(-1)\n",
    "\n",
    "            model = self.create_model(train_X, train_Y)\n",
    "            mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "            fit_gpytorch_model(mll)\n",
    "\n",
    "            UCB = UpperConfidenceBound(model, beta=0.1)\n",
    "            bounds_active = torch.stack([self.bounds[0][active_dims], self.bounds[1][active_dims]]).double()\n",
    "\n",
    "            candidate, _ = optimize_acqf(\n",
    "                UCB, bounds=bounds_active, q=1, num_restarts=10, raw_samples=100,\n",
    "                options={\"maxiter\": 200, \"batch_limit\": 5}\n",
    "            )\n",
    "\n",
    "            x_new = torch.zeros(self.dim, dtype=torch.double)\n",
    "            x_new[active_dims] = candidate.squeeze()\n",
    "            x_new[np.setdiff1d(range(self.dim), active_dims)] = self.best_x[\n",
    "                np.setdiff1d(range(self.dim), active_dims)]\n",
    "\n",
    "            y_new = self.obj_function(x_new.unsqueeze(0))\n",
    "\n",
    "            self.calculate_dimension_sensitivity()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pred = model(x_new[active_dims].unsqueeze(0))\n",
    "            sigma = pred.stddev.item()\n",
    "            self.sigma_history.append(sigma)\n",
    "\n",
    "            improvement = max(0, self.best_f - y_new.item())\n",
    "            self.update_bandit(active_dims, y_new.item())\n",
    "            self.improvement_history.append(improvement)\n",
    "\n",
    "            if y_new.item() < self.best_f:\n",
    "                self.best_f = y_new.item()\n",
    "                self.best_x = x_new\n",
    "\n",
    "            self.eval_history.append(self.best_f)\n",
    "\n",
    "        self.arm_selection_df = pd.DataFrame(self.arm_selection_history,\n",
    "                                             columns=[f'Arm_{i}' for i in range(self.dim)])\n",
    "        self.arm_selection_df.index.name = 'Iteration'\n",
    "\n",
    "        return self.best_x, self.best_f\n",
    "\n",
    "    def save_arm_selection_history(self, filename):\n",
    "        self.arm_selection_df.to_csv(filename)\n",
    "\n",
    "    def plot_sigma_history(self):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(range(1, len(self.sigma_history) + 1), self.sigma_history)\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Predicted Standard Deviation')\n",
    "        plt.title('Predicted Standard Deviation vs Iteration')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_dim_importance(self):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.bar(range(self.dim), self.dim_importance)\n",
    "        plt.xlabel('Dimension')\n",
    "        plt.ylabel('Importance')\n",
    "        plt.title('Dimension Importance')\n",
    "        plt.xticks(range(self.dim))\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_dim_sensitivity(self):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.bar(range(self.dim), self.dim_sensitivity)\n",
    "        plt.xlabel('Dimension')\n",
    "        plt.ylabel('Sensitivity')\n",
    "        plt.title('Dimension Sensitivity')\n",
    "        plt.xticks(range(self.dim))\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ],
   "outputs": [],
   "execution_count": 84
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8sX27BRBGUy"
   },
   "source": [
    "# 最適化の実行\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KlrVSaIvBJMm",
    "ExecuteTime": {
     "end_time": "2024-08-29T10:10:54.015793Z",
     "start_time": "2024-08-29T10:10:54.013177Z"
    }
   },
   "source": [
    "dim = 10\n",
    "active_dim = 5\n",
    "bounds = torch.tensor([[-5.0] * dim, [5.0] * dim])\n",
    "n_initial = 200\n",
    "n_iter = 500"
   ],
   "outputs": [],
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bFmsaVIdBMyY",
    "ExecuteTime": {
     "end_time": "2024-08-29T10:10:54.023249Z",
     "start_time": "2024-08-29T10:10:54.017843Z"
    }
   },
   "source": [
    "dropout_bo_mix = DropoutMixBO(dim, active_dim, bounds, n_initial, styblinski_tang, dropout_prob=0.1)\n",
    "dropout_bo_copy = DropoutMixBO(dim, active_dim, bounds, n_initial, styblinski_tang, dropout_prob=0.0)\n",
    "dropout_bo_random = DropoutMixBO(dim, active_dim, bounds, n_initial, styblinski_tang, dropout_prob=1.0)\n",
    "dropout_bandit_bc_ucb = DropoutMixBO_BC_UCB(dim, active_dim, bounds, n_initial, styblinski_tang, dropout_prob=0.0)\n",
    "rembo = REMBO(dim, active_dim, bounds, n_initial, styblinski_tang)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nomuyu\\AppData\\Local\\Temp\\ipykernel_22336\\16929139.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.X = torch.tensor(initial_X, dtype=torch.double)\n",
      "C:\\Users\\nomuyu\\AppData\\Local\\Temp\\ipykernel_22336\\16929139.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.Y = torch.tensor(initial_Y, dtype=torch.double)\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HbTD7Vr8BaU1",
    "outputId": "79b7b8af-12e7-4f18-8e72-b7c53c8da3fe",
    "ExecuteTime": {
     "end_time": "2024-08-29T10:11:07.399130Z",
     "start_time": "2024-08-29T10:10:54.030109Z"
    }
   },
   "source": [
    "try:\n",
    "  with tqdm.notebook.tqdm(total=100, bar_format=TQDM_BAR_FORMAT) as pbar:\n",
    "    with io.capture_output() as captured:\n",
    "      dropout_mix_best_x , dropout_mix_best_f = dropout_bo_mix.optimize(n_iter)\n",
    "      pbar.update(20)\n",
    "      dropout_copy_best_x , dropout_copy_best_f = dropout_bo_copy.optimize(n_iter)\n",
    "      pbar.update(20)\n",
    "      dropout_random_best_x , dropout_random_best_f = dropout_bo_random.optimize(n_iter)\n",
    "      pbar.update(20)\n",
    "      rembo_best_x, rembo_best_f = rembo.optimize(n_iter)\n",
    "      pbar.update(20) \n",
    "      pbar.update(10)\n",
    "      dropout_bandit_bc_ucb_best_x, dropout_bandit_bc_ucb_best_f = dropout_bandit_bc_ucb.optimize(n_iter)\n",
    "      dropout_bandit_bc_ucb.save_arm_selection_history('dropout_bandit_bc_ucb_arm_selection_binary.csv')\n",
    "      pbar.update(10)\n",
    "    \n",
    "except subprocess.CalledProcessError:\n",
    "  print(captured)\n",
    "  raise"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/100 [elapsed: 00:00 remaining: ?]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "35d4d2f76380413d8d07dafb3e2b34cd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[87], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tqdm\u001B[38;5;241m.\u001B[39mnotebook\u001B[38;5;241m.\u001B[39mtqdm(total\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, bar_format\u001B[38;5;241m=\u001B[39mTQDM_BAR_FORMAT) \u001B[38;5;28;01mas\u001B[39;00m pbar:\n\u001B[0;32m      3\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m io\u001B[38;5;241m.\u001B[39mcapture_output() \u001B[38;5;28;01mas\u001B[39;00m captured:\n\u001B[1;32m----> 4\u001B[0m     dropout_mix_best_x , dropout_mix_best_f \u001B[38;5;241m=\u001B[39m \u001B[43mdropout_bo_mix\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_iter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m     pbar\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;241m20\u001B[39m)\n\u001B[0;32m      6\u001B[0m     dropout_copy_best_x , dropout_copy_best_f \u001B[38;5;241m=\u001B[39m dropout_bo_copy\u001B[38;5;241m.\u001B[39moptimize(n_iter)\n",
      "Cell \u001B[1;32mIn[82], line 23\u001B[0m, in \u001B[0;36mDropoutMixBO.optimize\u001B[1;34m(self, n_iter)\u001B[0m\n\u001B[0;32m     21\u001B[0m model \u001B[38;5;241m=\u001B[39m create_model(train_X, train_Y)\n\u001B[0;32m     22\u001B[0m mll \u001B[38;5;241m=\u001B[39m ExactMarginalLogLikelihood(model\u001B[38;5;241m.\u001B[39mlikelihood, model)\n\u001B[1;32m---> 23\u001B[0m \u001B[43mfit_gpytorch_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmll\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     25\u001B[0m UCB \u001B[38;5;241m=\u001B[39m UpperConfidenceBound(model, beta\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m)\n\u001B[0;32m     26\u001B[0m bounds_active \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mstack([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbounds[\u001B[38;5;241m0\u001B[39m][active_dims], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbounds[\u001B[38;5;241m1\u001B[39m][active_dims]])\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\botorch\\fit.py:164\u001B[0m, in \u001B[0;36mfit_gpytorch_model\u001B[1;34m(mll, optimizer, optimizer_kwargs, exclude, max_retries, **kwargs)\u001B[0m\n\u001B[0;32m    158\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m (\n\u001B[0;32m    159\u001B[0m     nullcontext()\n\u001B[0;32m    160\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m exclude \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    161\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m requires_grad_ctx(mll, assignments\u001B[38;5;241m=\u001B[39m{name: \u001B[38;5;28;01mFalse\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m exclude})\n\u001B[0;32m    162\u001B[0m ):\n\u001B[0;32m    163\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 164\u001B[0m         mll \u001B[38;5;241m=\u001B[39m \u001B[43mfit_gpytorch_mll\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    165\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmll\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    166\u001B[0m \u001B[43m            \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    167\u001B[0m \u001B[43m            \u001B[49m\u001B[43moptimizer_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    168\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    169\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    170\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m ModelFittingError \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m    171\u001B[0m         warn(\u001B[38;5;28mstr\u001B[39m(err), \u001B[38;5;167;01mRuntimeWarning\u001B[39;00m)\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\botorch\\fit.py:105\u001B[0m, in \u001B[0;36mfit_gpytorch_mll\u001B[1;34m(mll, closure, optimizer, closure_kwargs, optimizer_kwargs, **kwargs)\u001B[0m\n\u001B[0;32m    102\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m optimizer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:  \u001B[38;5;66;03m# defer to per-method defaults\u001B[39;00m\n\u001B[0;32m    103\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moptimizer\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m optimizer\n\u001B[1;32m--> 105\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mFitGPyTorchMLL\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    106\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmll\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    107\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmll\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlikelihood\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    108\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmll\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    109\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclosure\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclosure\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    110\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclosure_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclosure_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    111\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimizer_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    112\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    113\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\botorch\\utils\\dispatcher.py:93\u001B[0m, in \u001B[0;36mDispatcher.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     91\u001B[0m func \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__getitem__\u001B[39m(types\u001B[38;5;241m=\u001B[39mtypes)\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 93\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m MDNotImplementedError:\n\u001B[0;32m     95\u001B[0m     \u001B[38;5;66;03m# Traverses registered methods in order, yields whenever a match is found\u001B[39;00m\n\u001B[0;32m     96\u001B[0m     funcs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_iter(\u001B[38;5;241m*\u001B[39mtypes)\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\botorch\\fit.py:252\u001B[0m, in \u001B[0;36m_fit_fallback\u001B[1;34m(mll, _, __, closure, optimizer, closure_kwargs, optimizer_kwargs, max_attempts, warning_handler, caught_exception_types, **ignore)\u001B[0m\n\u001B[0;32m    250\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m catch_warnings(record\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m warning_list, debug(\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m    251\u001B[0m     simplefilter(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124malways\u001B[39m\u001B[38;5;124m\"\u001B[39m, category\u001B[38;5;241m=\u001B[39mOptimizationWarning)\n\u001B[1;32m--> 252\u001B[0m     \u001B[43moptimizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmll\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclosure\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclosure\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43moptimizer_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    254\u001B[0m \u001B[38;5;66;03m# Resolved warnings and determine whether or not to retry\u001B[39;00m\n\u001B[0;32m    255\u001B[0m done \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\botorch\\optim\\fit.py:120\u001B[0m, in \u001B[0;36mfit_gpytorch_mll_scipy\u001B[1;34m(mll, parameters, bounds, closure, closure_kwargs, method, options, callback, timeout_sec)\u001B[0m\n\u001B[0;32m    117\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m closure_kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    118\u001B[0m     closure \u001B[38;5;241m=\u001B[39m partial(closure, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mclosure_kwargs)\n\u001B[1;32m--> 120\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mscipy_minimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    121\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclosure\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclosure\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    122\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    123\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    124\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    125\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    126\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    127\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout_sec\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_sec\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    128\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    129\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m!=\u001B[39m OptimizationStatus\u001B[38;5;241m.\u001B[39mSUCCESS:\n\u001B[0;32m    130\u001B[0m     warn(\n\u001B[0;32m    131\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`scipy_minimize` terminated with status \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;241m.\u001B[39mstatus\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, displaying\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    132\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m original message from `scipy.optimize.minimize`: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;241m.\u001B[39mmessage\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    133\u001B[0m         OptimizationWarning,\n\u001B[0;32m    134\u001B[0m     )\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\botorch\\optim\\core.py:109\u001B[0m, in \u001B[0;36mscipy_minimize\u001B[1;34m(closure, parameters, bounds, callback, x0, method, options, timeout_sec)\u001B[0m\n\u001B[0;32m    101\u001B[0m         result \u001B[38;5;241m=\u001B[39m OptimizationResult(\n\u001B[0;32m    102\u001B[0m             step\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mnext\u001B[39m(call_counter),\n\u001B[0;32m    103\u001B[0m             fval\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mfloat\u001B[39m(wrapped_closure(x)[\u001B[38;5;241m0\u001B[39m]),\n\u001B[0;32m    104\u001B[0m             status\u001B[38;5;241m=\u001B[39mOptimizationStatus\u001B[38;5;241m.\u001B[39mRUNNING,\n\u001B[0;32m    105\u001B[0m             runtime\u001B[38;5;241m=\u001B[39mmonotonic() \u001B[38;5;241m-\u001B[39m start_time,\n\u001B[0;32m    106\u001B[0m         )\n\u001B[0;32m    107\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m callback(parameters, result)  \u001B[38;5;66;03m# pyre-ignore [29]\u001B[39;00m\n\u001B[1;32m--> 109\u001B[0m raw \u001B[38;5;241m=\u001B[39m \u001B[43mminimize_with_timeout\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    110\u001B[0m \u001B[43m    \u001B[49m\u001B[43mwrapped_closure\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    111\u001B[0m \u001B[43m    \u001B[49m\u001B[43mwrapped_closure\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstate\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx0\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx0\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp_float64\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    112\u001B[0m \u001B[43m    \u001B[49m\u001B[43mjac\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    113\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbounds_np\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    114\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    115\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    116\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwrapped_callback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    117\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout_sec\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_sec\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    118\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    120\u001B[0m \u001B[38;5;66;03m# Post-processing and outcome handling\u001B[39;00m\n\u001B[0;32m    121\u001B[0m wrapped_closure\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m=\u001B[39m asarray(raw\u001B[38;5;241m.\u001B[39mx)  \u001B[38;5;66;03m# set parameter state to optimal values\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\botorch\\optim\\utils\\timeout.py:80\u001B[0m, in \u001B[0;36mminimize_with_timeout\u001B[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options, timeout_sec)\u001B[0m\n\u001B[0;32m     77\u001B[0m     wrapped_callback \u001B[38;5;241m=\u001B[39m callback\n\u001B[0;32m     79\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 80\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43moptimize\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mminimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     81\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfun\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfun\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     82\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx0\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx0\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     83\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     84\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     85\u001B[0m \u001B[43m        \u001B[49m\u001B[43mjac\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mjac\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     86\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhess\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhess\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     87\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhessp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhessp\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     88\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     89\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconstraints\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconstraints\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     90\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtol\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     91\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwrapped_callback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     92\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     93\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m OptimizationTimeoutError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     95\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOptimization timed out after \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;241m.\u001B[39mruntime\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m seconds.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:731\u001B[0m, in \u001B[0;36mminimize\u001B[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001B[0m\n\u001B[0;32m    728\u001B[0m     res \u001B[38;5;241m=\u001B[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001B[0;32m    729\u001B[0m                              \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n\u001B[0;32m    730\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m meth \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124ml-bfgs-b\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m--> 731\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43m_minimize_lbfgsb\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfun\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjac\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    732\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    733\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m meth \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtnc\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    734\u001B[0m     res \u001B[38;5;241m=\u001B[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001B[38;5;241m=\u001B[39mcallback,\n\u001B[0;32m    735\u001B[0m                         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:407\u001B[0m, in \u001B[0;36m_minimize_lbfgsb\u001B[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001B[0m\n\u001B[0;32m    401\u001B[0m task_str \u001B[38;5;241m=\u001B[39m task\u001B[38;5;241m.\u001B[39mtobytes()\n\u001B[0;32m    402\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m task_str\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFG\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m    403\u001B[0m     \u001B[38;5;66;03m# The minimization routine wants f and g at the current x.\u001B[39;00m\n\u001B[0;32m    404\u001B[0m     \u001B[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001B[39;00m\n\u001B[0;32m    405\u001B[0m     \u001B[38;5;66;03m# until the completion of the current minimization iteration.\u001B[39;00m\n\u001B[0;32m    406\u001B[0m     \u001B[38;5;66;03m# Overwrite f and g:\u001B[39;00m\n\u001B[1;32m--> 407\u001B[0m     f, g \u001B[38;5;241m=\u001B[39m \u001B[43mfunc_and_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    408\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m task_str\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNEW_X\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m    409\u001B[0m     \u001B[38;5;66;03m# new iteration\u001B[39;00m\n\u001B[0;32m    410\u001B[0m     n_iterations \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:343\u001B[0m, in \u001B[0;36mScalarFunction.fun_and_grad\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    341\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray_equal(x, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx):\n\u001B[0;32m    342\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_x(x)\n\u001B[1;32m--> 343\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_update_fun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    344\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_grad()\n\u001B[0;32m    345\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mg\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:294\u001B[0m, in \u001B[0;36mScalarFunction._update_fun\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    292\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_update_fun\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    293\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_updated:\n\u001B[1;32m--> 294\u001B[0m         fx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_wrapped_fun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    295\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m fx \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lowest_f:\n\u001B[0;32m    296\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lowest_x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:20\u001B[0m, in \u001B[0;36m_wrapper_fun.<locals>.wrapped\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m     16\u001B[0m ncalls[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m# Send a copy because the user may overwrite it.\u001B[39;00m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m# Overwriting results in undefined behaviour because\u001B[39;00m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001B[39;00m\n\u001B[1;32m---> 20\u001B[0m fx \u001B[38;5;241m=\u001B[39m \u001B[43mfun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m# Make sure the function returns a true scalar\u001B[39;00m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39misscalar(fx):\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:79\u001B[0m, in \u001B[0;36mMemoizeJac.__call__\u001B[1;34m(self, x, *args)\u001B[0m\n\u001B[0;32m     77\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, \u001B[38;5;241m*\u001B[39margs):\n\u001B[0;32m     78\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\" returns the function value \"\"\"\u001B[39;00m\n\u001B[1;32m---> 79\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compute_if_needed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     80\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_value\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:73\u001B[0m, in \u001B[0;36mMemoizeJac._compute_if_needed\u001B[1;34m(self, x, *args)\u001B[0m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39mall(x \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mjac \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(x)\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m---> 73\u001B[0m     fg \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     74\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mjac \u001B[38;5;241m=\u001B[39m fg[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m     75\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_value \u001B[38;5;241m=\u001B[39m fg[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\botorch\\optim\\closures\\core.py:150\u001B[0m, in \u001B[0;36mNdarrayOptimizationClosure.__call__\u001B[1;34m(self, state, **kwargs)\u001B[0m\n\u001B[0;32m    147\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m=\u001B[39m state\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m     value_tensor, grad_tensors \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclosure\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    151\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mas_array(value_tensor)\n\u001B[0;32m    152\u001B[0m     grads \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_gradient_ndarray(fill_value\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfill_value)\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\botorch\\optim\\closures\\core.py:66\u001B[0m, in \u001B[0;36mForwardBackwardClosure.__call__\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m     64\u001B[0m values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     65\u001B[0m value \u001B[38;5;241m=\u001B[39m values \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreducer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreducer(values)\n\u001B[1;32m---> 66\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     68\u001B[0m grads \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(param\u001B[38;5;241m.\u001B[39mgrad \u001B[38;5;28;01mfor\u001B[39;00m param \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparameters\u001B[38;5;241m.\u001B[39mvalues())\n\u001B[0;32m     69\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback:\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\torch\\_tensor.py:525\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    515\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    517\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    518\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    523\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    524\u001B[0m     )\n\u001B[1;32m--> 525\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    526\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    527\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    262\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    264\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    265\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    266\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 267\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    272\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    273\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    274\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    275\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    742\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    743\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 744\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    745\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[0;32m    746\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    747\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    748\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 87
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## アームの履歴 BC_UCBのバンディット"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T10:11:07.400151Z",
     "start_time": "2024-08-29T10:11:07.400151Z"
    }
   },
   "source": [
    "# Load the saved CSV file\n",
    "df = pd.read_csv(\"dropout_bandit_bc_ucb_arm_selection_binary.csv\", index_col=\"Iteration\")\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Calculate arm selection frequency\n",
    "arm_freq = df.sum().sort_values(ascending=False)\n",
    "\n",
    "# Create a bar plot of arm selection frequency\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=arm_freq.index, y=arm_freq.values)\n",
    "plt.title(\"Arm Selection Frequency (BC-UCB)\")\n",
    "plt.xlabel(\"Arm\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create a heatmap of arm selection over iterations\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df.T, cmap=\"YlOrRd\", cbar_kws={'label': 'Selected'})\n",
    "plt.title(\"Arm Selection Over Iterations (BC-UCB)\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Arm\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout_Banditのimprovementのプロット"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T10:11:07.401149Z",
     "start_time": "2024-08-29T10:11:07.400151Z"
    }
   },
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(dropout_bandit_bc_ucb.improvement_history)), dropout_bandit_bc_ucb.improvement_history, label='Dropout-Bandit-BC-UCB')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Improvement')\n",
    "plt.title('Improvement vs Iteration')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout_Banditのsigmaのプロット"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "dropout_bandit_bc_ucb.plot_sigma_history()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout_Banditの次元重要度のプロット"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "dropout_bandit_bc_ucb.plot_dim_importance()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b046tAbcBxyU"
   },
   "source": [
    "# 結果のプロット"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "id": "4nCY_jN2BveQ",
    "outputId": "4ec6730f-0ad0-4e71-a860-3cc0e3205a28"
   },
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(range(1, n_initial + n_iter + 1), dropout_bo_mix.eval_history, label='Dropout-Mix BO')\n",
    "plt.plot(range(1, n_initial + n_iter + 1), dropout_bo_copy.eval_history, label='Dropout-Copy BO')\n",
    "plt.plot(range(1, n_initial + n_iter + 1), dropout_bo_random.eval_history, label='Dropout-Random BO')\n",
    "plt.plot(range(1, n_initial + n_iter + 1), rembo.eval_history, label='REMBO')\n",
    "plt.plot(range(1, n_initial + n_iter + 1), dropout_bandit_bc_ucb.eval_history, label='Dropout-Bandit-BC-UCB BO')\n",
    "plt.axhline(y=global_optimum, color='r', linestyle='--', label='Global Optimum')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Best Function Value')\n",
    "plt.title('Comparison of Optimization Algorithms　for Rosenbrock Function')\n",
    "plt.legend()\n",
    "plt.yscale('symlog')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0af17b96dece47eca9ca9d7be6dc63b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1afa0f53e6f740aa844484642c3d80c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1b55749b3fa043b8a6fd555305db2944",
       "IPY_MODEL_70740e89fa304143b3e7b3a4a0cd87ad",
       "IPY_MODEL_e63abcaacc6449039d73b58d7296265e"
      ],
      "layout": "IPY_MODEL_496ad9319d8243d280de82a7b1076962"
     }
    },
    "1b55749b3fa043b8a6fd555305db2944": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_84a211d6ea5a49e4861bbe0d4bc48a8b",
      "placeholder": "​",
      "style": "IPY_MODEL_b6bf801aeaff419ea299d38dcfdd4897",
      "value": "100%"
     }
    },
    "496ad9319d8243d280de82a7b1076962": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4bdb725ab6284f468a9d718aa13bd69d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "70740e89fa304143b3e7b3a4a0cd87ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0af17b96dece47eca9ca9d7be6dc63b0",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a51f753d216a4f548c43c058db765d34",
      "value": 100
     }
    },
    "72625ba6d5ac46f8b6efea358be8cf59": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84a211d6ea5a49e4861bbe0d4bc48a8b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a51f753d216a4f548c43c058db765d34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b6bf801aeaff419ea299d38dcfdd4897": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e63abcaacc6449039d73b58d7296265e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_72625ba6d5ac46f8b6efea358be8cf59",
      "placeholder": "​",
      "style": "IPY_MODEL_4bdb725ab6284f468a9d718aa13bd69d",
      "value": " 100/100 [elapsed: 00:45 remaining: 00:00]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
