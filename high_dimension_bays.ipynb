{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T20:43:26.126078Z",
     "start_time": "2024-09-24T20:43:26.123202Z"
    }
   },
   "source": [
    "from IPython.utils import io\n",
    "import os\n",
    "import subprocess\n",
    "import tqdm.notebook\n",
    "\n",
    "TQDM_BAR_FORMAT = '{l_bar}{bar}| {n_fmt}/{total_fmt} [elapsed: {elapsed} remaining: {remaining}]'\n"
   ],
   "outputs": [],
   "execution_count": 519
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5b0mNZdUCUhZ",
    "ExecuteTime": {
     "end_time": "2024-09-24T20:43:26.194686Z",
     "start_time": "2024-09-24T20:43:26.191588Z"
    }
   },
   "source": [
    "import torch\n",
    "from botorch import fit_gpytorch_model\n",
    "from botorch.acquisition import UpperConfidenceBound\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.optim import optimize_acqf\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from gpytorch.kernels import RBFKernel, ScaleKernel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import softmax\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from botorch.models import SaasFullyBayesianSingleTaskGP\n",
    "from gpytorch.kernels import MaternKernel, ScaleKernel\n",
    "from botorch.acquisition import ExpectedImprovement\n",
    "from gpytorch import constraints"
   ],
   "outputs": [],
   "execution_count": 520
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6vSA03y-DlJ"
   },
   "source": [
    "# 目的関数の用意 (Rosenbrock関数)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bXL2EF3t-Jlj",
    "ExecuteTime": {
     "end_time": "2024-09-24T20:43:26.198391Z",
     "start_time": "2024-09-24T20:43:26.195693Z"
    }
   },
   "source": [
    "def styblinski_tang(x):\n",
    "    indices = [0, 1, 2, 3, 4]\n",
    "    x_selected = x[..., indices]\n",
    "    return 0.5 * torch.sum(x_selected ** 4 - 16 * x_selected ** 2 + 5 * x_selected, dim=-1)"
   ],
   "outputs": [],
   "execution_count": 521
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "d3CnViCV-O8t",
    "ExecuteTime": {
     "end_time": "2024-09-24T20:43:26.212311Z",
     "start_time": "2024-09-24T20:43:26.210544Z"
    }
   },
   "source": [
    "# styblinski_tang関数の最適解\n",
    "global_optimum = -39.16599 * 5"
   ],
   "outputs": [],
   "execution_count": 522
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8w-P5Vpg-s1_"
   },
   "source": [
    "# 初期点の生成関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XMsy_wo-yTR"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "i2mpt0XN-ys4",
    "ExecuteTime": {
     "end_time": "2024-09-24T20:43:26.225163Z",
     "start_time": "2024-09-24T20:43:26.221317Z"
    }
   },
   "source": [
    "def generate_initial_points(n_initial, dim, bounds):\n",
    "    return torch.rand(n_initial, dim) * (bounds[1] - bounds[0]) + bounds[0]"
   ],
   "outputs": [],
   "execution_count": 523
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-U8hGE6G-7jh"
   },
   "source": [
    "# モデル作成関数\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "k05lLlt9-6fL",
    "ExecuteTime": {
     "end_time": "2024-09-24T20:43:26.238539Z",
     "start_time": "2024-09-24T20:43:26.235300Z"
    }
   },
   "source": [
    "def create_model(train_X, train_Y):\n",
    "    kernel = ScaleKernel(RBFKernel(ard_num_dims=train_X.shape[-1], noise_constraint=1e-5))\n",
    "    model = SingleTaskGP(train_X, train_Y, covar_module=kernel)\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 524
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCc5R9W7_BmY"
   },
   "source": [
    "# ドロップアウトベイズクラス"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bAATR5uq_Jb6",
    "ExecuteTime": {
     "end_time": "2024-09-24T20:43:26.273876Z",
     "start_time": "2024-09-24T20:43:26.268430Z"
    }
   },
   "source": [
    "class DropoutMixBO:\n",
    "    def __init__(self, dim, active_dim, bounds, n_initial, obj_function, dropout_prob=0.1):\n",
    "\n",
    "        self.dim = dim  # 全体の次元数\n",
    "        self.active_dim = active_dim  # 活性化する次元数\n",
    "        self.bounds = bounds  # 各次元の探索範囲\n",
    "        self.obj_function = obj_function  # 最適化したい目的関数\n",
    "        self.dropout_prob = dropout_prob  # ドロップアウトの確率\n",
    "        self.X = generate_initial_points(n_initial, dim, bounds)  # 初期点を生成\n",
    "        self.Y = self.obj_function(self.X)  # 初期点での目的関数の値を計算\n",
    "        self.best_f = self.Y.min().item()  # 現在の最良の目的関数値\n",
    "        self.best_x = self.X[self.Y.argmin()]  # 現在の最良の解\n",
    "        self.eval_history = [self.best_f] * n_initial  # 評価履歴を初期化\n",
    "\n",
    "    def optimize(self, n_iter):\n",
    "        for _ in range(n_iter):  # 指定された回数だけ最適化を繰り返す\n",
    "            # 全次元からランダムにactive_dim個選ぶ\n",
    "            active_dims = np.random.choice(self.dim, self.active_dim, replace=False)\n",
    "\n",
    "            train_X = self.X[:, active_dims].float()  # 選んだ次元のデータだけ抽出\n",
    "            train_Y = self.Y.unsqueeze(-1).float()  # Yの形状を調整\n",
    "            \n",
    "            model = create_model(train_X, train_Y)  # GPモデルを作成\n",
    "            mll = ExactMarginalLogLikelihood(model.likelihood, model)  # 尤度関数を定義\n",
    "            fit_gpytorch_model(mll)  # モデルを学習\n",
    "\n",
    "            EI = ExpectedImprovement(model, best_f=self.best_f, maximize=False)  # Expected Improvementを定義\n",
    "            bounds_active = torch.stack([self.bounds[0][active_dims], self.bounds[1][active_dims]]).float()  # 活性化次元の探索範囲を定義\n",
    "            \n",
    "            candidate, _ = optimize_acqf(  # 獲得関数を最適化して次の候補点を見つける\n",
    "                EI, bounds=bounds_active, q=1, num_restarts=10, raw_samples=100,\n",
    "            )\n",
    "\n",
    "            x_new = torch.zeros(self.dim)  # 新しい候補点を初期化\n",
    "            if np.random.random() < self.dropout_prob:  # ドロップアウトを適用するかどうか決める\n",
    "                x_new[active_dims] = candidate.squeeze()  # 活性化次元に候補点の値を設定\n",
    "                inactive_dims = np.setdiff1d(range(self.dim), active_dims)  # 非活性化次元を特定\n",
    "                x_new[inactive_dims] = (torch.rand(len(inactive_dims))  # 非活性化次元にランダムな値を設定\n",
    "                                        * (self.bounds[1][inactive_dims] - self.bounds[0][inactive_dims])\n",
    "                                        + self.bounds[0][inactive_dims])\n",
    "            else:\n",
    "                x_new[active_dims] = candidate.squeeze()  # 活性化次元に候補点の値を設定\n",
    "                x_new[np.setdiff1d(range(self.dim), active_dims)] = self.best_x[  # 非活性化次元に最良解の値を設定\n",
    "                    np.setdiff1d(range(self.dim), active_dims)]\n",
    "\n",
    "            y_new = self.obj_function(x_new.unsqueeze(0))  # 新しい候補点での目的関数値を計算\n",
    "\n",
    "            self.X = torch.cat([self.X, x_new.unsqueeze(0)])  # データセットに新しい点を追加\n",
    "            self.Y = torch.cat([self.Y, y_new])  # 目的関数値のリストに新しい値を追加\n",
    "\n",
    "            if y_new < self.best_f:  # もし新しい点が今までの最良値より良ければ\n",
    "                self.best_f = y_new.item()  # 最良値を更新\n",
    "                self.best_x = x_new  # 最良解を更新\n",
    "\n",
    "            self.eval_history.append(self.best_f)  # 評価履歴に現在の最良値を追加\n",
    "\n",
    "        return self.best_x, self.best_f  # 最適化が終わったら最良解と最良値を返す"
   ],
   "outputs": [],
   "execution_count": 525
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# fullバンディットアルゴリズムを取り入れたDropoutMixBOクラス"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T20:43:26.286673Z",
     "start_time": "2024-09-24T20:43:26.273876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DropoutMixEST1BO:\n",
    "    def __init__(self, dim, active_dim, bounds, n_initial, obj_function, dropout_prob=0.1, delta=0.1):\n",
    "        self.dim = dim  # 全次元数\n",
    "        self.active_dim = active_dim  # 活性化する次元数\n",
    "        self.bounds = bounds  # 各次元の探索範囲\n",
    "        self.obj_function = obj_function  # 最適化したい目的関数\n",
    "        self.dropout_prob = dropout_prob  # ドロップアウトの確率\n",
    "        self.delta = delta  # 信頼度\n",
    "        self.X = generate_initial_points(n_initial, dim, bounds).float()  # 初期点を生成\n",
    "        self.Y = self.obj_function(self.X).float()  # 初期点での目的関数の値を計算\n",
    "        self.best_f = self.Y.min().item()  # 現在の最良の目的関数値\n",
    "        self.best_x = self.X[self.Y.argmin()]  # 現在の最良の解\n",
    "        self.eval_history = [self.best_f] * n_initial  # 評価履歴を初期化\n",
    "        self.improvement_history = [] # 報酬の履歴を初期化\n",
    "        self.iteration = 0  # 現在のイテレーション\n",
    "\n",
    "        # CSARアルゴリズムの初期化\n",
    "        self.N = list(range(self.dim))  # 全次元の集合\n",
    "        self.accepted_dims = []  # 受理された次元\n",
    "        self.rejected_dims = []  # 除外された次元\n",
    "        self.remaining_dims = self.N.copy()  # 残りの次元\n",
    "        self.theta_hat = np.zeros(self.dim)  # 各次元の推定報酬\n",
    "        self.phase = 1  # 現在のフェーズ\n",
    "        self.epsilon_t = 0.5  # 初期の精度レベル\n",
    "        self.delta_t = (6 / np.pi ** 2) * self.delta  # 初期の信頼度レベル\n",
    "\n",
    "    def EST1(self, N_t, k, epsilon_t, delta_t):\n",
    "        n = len(N_t)\n",
    "        # サンプル数を計算（m は 1 としていますが、必要に応じて調整してください）\n",
    "        m = 1\n",
    "        # N_t をサイズ 2k の部分集合に分割\n",
    "        num_subsets = int(np.ceil(n / (2 * k)))\n",
    "        subsets = []\n",
    "        for i in range(num_subsets):\n",
    "            subset = N_t[i * 2 * k:(i + 1) * 2 * k]\n",
    "            if len(subset) < 2 * k:\n",
    "                # 次元が足りない場合は繰り返しで埋める\n",
    "                subset += subset[:(2 * k - len(subset))]\n",
    "            subsets.append(subset)\n",
    "\n",
    "        # 推定報酬と出現回数を初期化\n",
    "        theta_hat = np.zeros(n)\n",
    "        counts = np.zeros(n)\n",
    "\n",
    "        # 各部分集合について推定を行う\n",
    "        for subset in subsets:\n",
    "            # サイズ 2k のハダマード行列を作成\n",
    "            H = self.create_hadamard(2 * k)\n",
    "            Z_hat = np.zeros(2 * k)\n",
    "\n",
    "            # subset 内の次元を N_t のインデックスにマッピング\n",
    "            subset_indices = [N_t.index(dim) for dim in subset]\n",
    "\n",
    "            # ハダマード行列に従って部分集合をサンプリング\n",
    "            for i in range(2 * k):\n",
    "                h_row = H[i]\n",
    "                if i == 0:\n",
    "                    pos_dims = subset[:k]\n",
    "                    neg_dims = subset[k:2 * k]\n",
    "                else:\n",
    "                    pos_dims = [subset[j] for j in range(2 * k) if h_row[j] == 1]\n",
    "                    neg_dims = [subset[j] for j in range(2 * k) if h_row[j] == -1]\n",
    "\n",
    "                pos_samples = []\n",
    "                neg_samples = []\n",
    "\n",
    "                for l in range(m):\n",
    "                    # 正の次元の報酬をサンプリング\n",
    "                    if len(pos_dims) > 0:\n",
    "                        pos_sample = self.predict_without_x(pos_dims)\n",
    "                        pos_samples.append(pos_sample)\n",
    "                    else:\n",
    "                        # pos_dims が空の場合、デフォルト値を使用（例として0を使用）\n",
    "                        pos_samples.append(0)\n",
    "\n",
    "                    # 負の次元の報酬をサンプリング\n",
    "                    if len(neg_dims) > 0:\n",
    "                        neg_sample = self.predict_without_x(neg_dims)\n",
    "                        neg_samples.append(neg_sample)\n",
    "                    else:\n",
    "                        # neg_dims が空の場合、デフォルト値を使用（例として0を使用）\n",
    "                        neg_samples.append(0)\n",
    "\n",
    "                # 正の次元と負の次元の報酬の平均を計算\n",
    "                mu_pos = np.mean(pos_samples) if len(pos_samples) > 0 else 0\n",
    "                mu_neg = np.mean(neg_samples) if len(neg_samples) > 0 else 0\n",
    "\n",
    "                if i == 0:\n",
    "                    Z_hat[i] = mu_pos + mu_neg\n",
    "                else:\n",
    "                    Z_hat[i] = mu_pos - mu_neg\n",
    "\n",
    "            # ハダマード行列を用いて次元ごとの報酬を推定\n",
    "            theta_subset = (1 / (2 * k)) * H.T @ Z_hat\n",
    "\n",
    "            # 推定された報酬を theta_hat に反映し、出現回数を更新\n",
    "            for idx, dim_idx in enumerate(subset_indices):\n",
    "                theta_hat[dim_idx] += theta_subset[idx]\n",
    "                counts[dim_idx] += 1\n",
    "\n",
    "        # 各次元の推定報酬の平均を計算\n",
    "        theta_hat = theta_hat / counts\n",
    "\n",
    "        return theta_hat\n",
    "\n",
    "    def create_hadamard(self, n):\n",
    "        # サイズnのハダマード行列を作成（nは2の累乗）\n",
    "        assert n & (n - 1) == 0, \"ハダマード行列のサイズは2の累乗である必要があります\"\n",
    "        H = np.array([[1]])\n",
    "        while H.shape[0] < n:\n",
    "            H = np.block([[H, H], [H, -H]])\n",
    "        return H\n",
    "\n",
    "    def predict(self, X, active_dims):\n",
    "        # GPモデルを使用して予測を行う\n",
    "        train_X = self.X[:, active_dims].float()\n",
    "        train_Y = self.Y.unsqueeze(-1).float()\n",
    "        model = create_model(train_X, train_Y)\n",
    "        mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "        fit_gpytorch_model(mll)\n",
    "        model.eval()\n",
    "        self.iteration += 1\n",
    "        print(self.iteration)\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(X.float()).mean.item()\n",
    "        return y_pred\n",
    "\n",
    "    def predict_without_x(self, active_dims):\n",
    "        # GPモデルを使用して予測を行う\n",
    "        train_X = self.X[:, active_dims].float()\n",
    "        train_Y = self.Y.unsqueeze(-1).float()\n",
    "        model = create_model(train_X, train_Y)\n",
    "        mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "        fit_gpytorch_model(mll)\n",
    "        model.eval()\n",
    "        self.iteration += 1\n",
    "        print(self.iteration)\n",
    "\n",
    "        # Expected Improvement (EI) 獲得関数の定義\n",
    "        EI = ExpectedImprovement(model, best_f=self.best_f, maximize=False)\n",
    "        bounds_active = torch.stack([self.bounds[0][active_dims], self.bounds[1][active_dims]]).float()\n",
    "\n",
    "        # 獲得関数の最適化\n",
    "        candidate, _ = optimize_acqf(\n",
    "            EI, bounds=bounds_active, q=1, num_restarts=10, raw_samples=100,\n",
    "            options={\"maxiter\": 200, \"batch_limit\": 5}\n",
    "        )\n",
    "\n",
    "        # 新しい候補点を構築\n",
    "        x_new = torch.zeros(self.dim, dtype=torch.float32)\n",
    "        x_new[active_dims] = candidate.squeeze()\n",
    "        x_new[np.setdiff1d(range(self.dim), active_dims)] = self.best_x[\n",
    "            np.setdiff1d(range(self.dim), active_dims)]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(x_new[active_dims].unsqueeze(0).float()).mean.item()\n",
    "        return y_pred\n",
    "\n",
    "        # 目的関数の評価\n",
    "        y_new = self.obj_function(x_new.unsqueeze(0))\n",
    "        if isinstance(y_new, torch.Tensor):\n",
    "            y_new = y_new.item()\n",
    "\n",
    "        improvement = np.exp(-((y_pred - y_new) ** 2))\n",
    "        self.improvement_history.append(improvement)\n",
    "\n",
    "        # 活性化次元の推定報酬を更新\n",
    "        for dim in active_dims:\n",
    "            self.theta_hat[dim] = (self.theta_hat[dim] + improvement) / 2  # 平均を取る\n",
    "\n",
    "        # データセットに新しい点を追加\n",
    "        self.X = torch.cat([self.X, x_new.unsqueeze(0)])\n",
    "        self.Y = torch.cat([self.Y, y_new])\n",
    "\n",
    "        # 最良の解を更新\n",
    "        if y_new < self.best_f:\n",
    "            self.best_f = y_new.item()\n",
    "            self.best_x = x_new\n",
    "\n",
    "        self.eval_history.append(self.best_f)\n",
    "\n",
    "        return improvement\n",
    "\n",
    "    def optimize(self, n_iter):\n",
    "        while self.iteration < n_iter:\n",
    "            # CSARアルゴリズムの実行\n",
    "            while len(self.remaining_dims) + len(self.accepted_dims) > self.active_dim:\n",
    "                # 推定アルゴリズムEST1を使用して報酬を推定\n",
    "                theta_hat_t = self.EST1(self.remaining_dims, self.active_dim, self.epsilon_t, self.delta_t)\n",
    "                # 推定報酬に基づいて次元をソート\n",
    "                sorted_indices = np.argsort(-theta_hat_t)\n",
    "                sorted_dims = [self.remaining_dims[i] for i in sorted_indices]\n",
    "\n",
    "                # 受理および除外する次元を決定\n",
    "                theta_k = theta_hat_t[sorted_indices[self.active_dim - 1]]\n",
    "                theta_k_plus_1 = theta_hat_t[sorted_indices[self.active_dim]] if len(sorted_dims) > self.active_dim else -np.inf\n",
    "\n",
    "                # A = [sorted_dims[i] for i in range(len(sorted_dims)) if theta_hat_t[sorted_indices[i]] - theta_k_plus_1 > 2 * self.epsilon_t]\n",
    "                # R = [sorted_dims[i] for i in range(len(sorted_dims)) if theta_k - theta_hat_t[sorted_indices[i]] > 2 * self.epsilon_t]\n",
    "\n",
    "                # m = 1 のときのepsilon_t\n",
    "                epsilon_m1 = np.sqrt(2 * np.log(len(self.remaining_dims) / self.delta_t) )\n",
    "\n",
    "                A = []\n",
    "                R = [sorted_dims[i] for i in range(len(sorted_dims)) if theta_k - theta_hat_t[sorted_indices[i]] > 2 * epsilon_m1]\n",
    "\n",
    "                #self.accepted_dims.extend(A)\n",
    "                self.rejected_dims.extend(R)\n",
    "                self.remaining_dims = [dim for dim in self.remaining_dims if dim not in A and dim not in R]\n",
    "\n",
    "                # 精度と信頼度を更新\n",
    "                self.phase += 1\n",
    "                self.epsilon_t /= 2\n",
    "                self.delta_t = (6 / (np.pi ** 2)) * (self.delta / (self.phase ** 2))\n",
    "\n",
    "                # 必要な次元数が揃ったらループを抜ける\n",
    "                if len(self.accepted_dims) >= self.active_dim:\n",
    "                    break\n",
    "\n",
    "            # 活性化次元を決定\n",
    "            if len(self.accepted_dims) >= self.active_dim:\n",
    "                active_dims = self.accepted_dims[:self.active_dim]\n",
    "            else:\n",
    "                active_dims = self.accepted_dims + self.remaining_dims[:(self.active_dim - len(self.accepted_dims))]\n",
    "\n",
    "            active_dims = active_dims[:self.active_dim]  # 必要に応じて調整\n",
    "\n",
    "            # 次のイテレーションのためにリセット\n",
    "            self.remaining_dims = self.N.copy()\n",
    "            self.accepted_dims = []\n",
    "            self.rejected_dims = []\n",
    "            self.phase = 1\n",
    "            self.epsilon_t = 0.5\n",
    "            self.delta_t = (6 / np.pi ** 2) * self.delta\n",
    "\n",
    "        return self.best_x, self.best_f"
   ],
   "outputs": [],
   "execution_count": 526
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# そのままベイズ最適化クラス"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T20:43:26.293336Z",
     "start_time": "2024-09-24T20:43:26.286673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BasicBO:\n",
    "    def __init__(self, dim, bounds, n_initial, obj_function):\n",
    "        self.dim = dim  # 次元数\n",
    "        self.bounds = bounds  # 各次元の探索範囲\n",
    "        self.obj_function = obj_function  # 最適化したい目的関数\n",
    "        self.X = generate_initial_points(n_initial, dim, bounds).float()  # 初期点を生成\n",
    "        self.Y = self.obj_function(self.X).float()  # 初期点での目的関数の値を計算\n",
    "        self.best_f = self.Y.min().item()  # 現在の最良の目的関数値\n",
    "        self.best_x = self.X[self.Y.argmin()]  # 現在の最良の解\n",
    "        self.eval_history = [self.best_f] * n_initial  # 評価履歴を初期化\n",
    "\n",
    "    def optimize(self, n_iter):\n",
    "        for _ in range(n_iter):  # 指定された回数だけ最適化を繰り返す\n",
    "            train_X = self.X  # すべての次元のデータを使用\n",
    "            train_Y = self.Y.unsqueeze(-1)  # Yの形状を調整\n",
    "            \n",
    "            model = create_model(train_X, train_Y)  # GPモデルを作成\n",
    "            mll = ExactMarginalLogLikelihood(model.likelihood, model)  # 尤度関数を定義\n",
    "            fit_gpytorch_model(mll)  # モデルを学習\n",
    "\n",
    "            EI = ExpectedImprovement(model, best_f=self.best_f, maximize=False)  # Expected Improvementを定義\n",
    "            bounds = torch.stack([self.bounds[0], self.bounds[1]]).float()  # 探索範囲を定義\n",
    "            \n",
    "            candidate, _ = optimize_acqf(  # 獲得関数を最適化して次の候補点を見つける\n",
    "                EI, bounds=bounds, q=1, num_restarts=10, raw_samples=100,\n",
    "            )\n",
    "\n",
    "            x_new = candidate.squeeze()  # 新しい候補点\n",
    "\n",
    "            y_new = self.obj_function(x_new.unsqueeze(0))  # 新しい候補点での目的関数値を計算\n",
    "\n",
    "            self.X = torch.cat([self.X, x_new.unsqueeze(0)])  # データセットに新しい点を追加\n",
    "            self.Y = torch.cat([self.Y, y_new])  # 目的関数値のリストに新しい値を追加\n",
    "\n",
    "            if y_new < self.best_f:  # もし新しい点が今までの最良値より良ければ\n",
    "                self.best_f = y_new.item()  # 最良値を更新\n",
    "                self.best_x = x_new  # 最良解を更新\n",
    "\n",
    "            self.eval_history.append(self.best_f)  # 評価履歴に現在の最良値を追加\n",
    "\n",
    "        return self.best_x, self.best_f  # 最適化が終わったら最良解と最良値を返す"
   ],
   "outputs": [],
   "execution_count": 527
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REMBO"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T20:43:26.309637Z",
     "start_time": "2024-09-24T20:43:26.304478Z"
    }
   },
   "source": [
    "class REMBO:\n",
    "    def __init__(self, high_dim, low_dim, bounds, n_initial, obj_function):\n",
    "        assert high_dim >= low_dim, \"high_dim must be greater than or equal to low_dim\"\n",
    "\n",
    "        self.high_dim = high_dim\n",
    "        self.low_dim = low_dim\n",
    "        self.bounds = bounds\n",
    "        self.obj_function = obj_function\n",
    "        \n",
    "        # すべてのテンソルをdouble型に変更\n",
    "        self.A = torch.randn(high_dim, low_dim, dtype=torch.double)\n",
    "        \n",
    "        self.X_low = (torch.randn(n_initial, low_dim, dtype=torch.double) * 2 - 1)\n",
    "        \n",
    "        self.X_high = torch.clamp(self.X_low @ self.A.t(), bounds[0], bounds[1])\n",
    "        assert self.X_high.shape == (n_initial, high_dim), f\"Expected shape {(n_initial, high_dim)}, but got {self.X_high.shape}\"\n",
    "        \n",
    "        self.Y = self.obj_function(self.X_high)\n",
    "        \n",
    "        self.best_f = self.Y.min().item()\n",
    "        self.best_x = self.X_high[self.Y.argmin()]\n",
    "        self.eval_history = [self.best_f] * n_initial\n",
    "\n",
    "    def optimize(self, n_iter):\n",
    "        for _ in range(n_iter):\n",
    "            train_X_low = self.X_low\n",
    "            train_Y = self.Y.unsqueeze(-1)\n",
    "            model = SingleTaskGP(train_X_low, train_Y)\n",
    "            mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "            fit_gpytorch_model(mll)\n",
    "\n",
    "            UCB = UpperConfidenceBound(model, beta=0.1)\n",
    "            \n",
    "            bounds_low = torch.stack([torch.ones(self.low_dim, dtype=torch.double) * -1, torch.ones(self.low_dim, dtype=torch.double)])\n",
    "            candidate_low, _ = optimize_acqf(\n",
    "                UCB, bounds=bounds_low, q=1, num_restarts=5, raw_samples=20,\n",
    "            )\n",
    "\n",
    "            x_high = torch.clamp(candidate_low @ self.A.t(), self.bounds[0], self.bounds[1])\n",
    "            y_new = self.obj_function(x_high)\n",
    "\n",
    "            self.X_low = torch.cat([self.X_low, candidate_low])\n",
    "            self.X_high = torch.cat([self.X_high, x_high])\n",
    "            self.Y = torch.cat([self.Y, y_new])\n",
    "\n",
    "            if y_new < self.best_f:\n",
    "                self.best_f = y_new.item()\n",
    "                self.best_x = x_high.squeeze()\n",
    "\n",
    "            self.eval_history.append(self.best_f)\n",
    "\n",
    "        return self.best_x, self.best_f"
   ],
   "outputs": [],
   "execution_count": 528
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# バンディットアルゴリズムを取り入れたDropoutMixBOクラス"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T20:43:26.356230Z",
     "start_time": "2024-09-24T20:43:26.347003Z"
    }
   },
   "source": [
    "class DropoutMixBO_BC:\n",
    "    def __init__(self, dim, active_dim, bounds, n_initial, obj_function, dropout_prob=0.0, epsilon=0.1,\n",
    "                 temperature=1e-3, reset_interval=1000, learning_rate=0.005, initial_beta=2.0, annealing_rate=1000):\n",
    "        # クラスの初期化\n",
    "        self.dim = dim\n",
    "        self.active_dim = active_dim\n",
    "        self.bounds = bounds\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.obj_function = obj_function\n",
    "        self.epsilon = epsilon\n",
    "        self.temperature = temperature\n",
    "        self.reset_interval = reset_interval\n",
    "        self.iteration = 0\n",
    "        self.learning_rate = learning_rate\n",
    "        self.initial_beta = initial_beta\n",
    "        self.annealing_rate = annealing_rate\n",
    "\n",
    "        # 初期点の生成と評価\n",
    "        initial_X = generate_initial_points(n_initial, dim, bounds)\n",
    "        initial_Y = obj_function(initial_X)\n",
    "\n",
    "        self.X = initial_X.double()\n",
    "        self.Y = initial_Y.double()\n",
    "\n",
    "        self.best_f = self.Y.min().item()\n",
    "        self.best_x = self.X[self.Y.argmin()]\n",
    "        self.eval_history = [self.best_f] * n_initial\n",
    "        self.improvement_history = []\n",
    "\n",
    "        self.arm_rewards = np.zeros(dim)\n",
    "        self.arm_counts = np.zeros(dim)\n",
    "        self.total_pulls = 0\n",
    "        self.dim_sensitivity = np.zeros(dim)\n",
    "\n",
    "        self.arm_selection_history = []\n",
    "\n",
    "\n",
    "    def select_active_dims(self):\n",
    "        # 活性化する次元を選択\n",
    "        self.iteration += 1\n",
    "\n",
    "        # UCBスコアに基づいて選択\n",
    "        ucb_scores = self.calculate_ucb_scores()\n",
    "\n",
    "        # ソフトマックスの適用\n",
    "        probabilities = softmax(ucb_scores / self.temperature)\n",
    "        probabilities = np.nan_to_num(probabilities, nan=1.0 / self.dim, posinf=1.0, neginf=0.0)\n",
    "        probabilities = np.clip(probabilities, 1e-10, 1)\n",
    "        probabilities /= probabilities.sum()\n",
    "\n",
    "        selected_arms = np.random.choice(self.dim, self.active_dim, replace=False, p=probabilities)\n",
    "\n",
    "        # 選択された次元を記録\n",
    "        arm_selection = np.zeros(self.dim)\n",
    "        arm_selection[selected_arms] = 1\n",
    "        self.arm_selection_history.append(arm_selection)\n",
    "\n",
    "        return selected_arms\n",
    "\n",
    "    def calculate_ucb_scores(self):\n",
    "        # UCBスコアを計算\n",
    "        exploration_term = np.sqrt(2 * np.log(self.total_pulls + 1) / (self.arm_counts + 1e-5))\n",
    "        exploitation_term = self.arm_rewards / (self.arm_counts + 1e-5)\n",
    "\n",
    "        # アニーリングによるβの調整\n",
    "        beta = self.initial_beta * np.exp(-self.iteration / self.annealing_rate)\n",
    "\n",
    "        ucb_scores = exploitation_term + beta * exploration_term\n",
    "        return ucb_scores \n",
    "\n",
    "    def calculate_dimension_sensitivity(self, new_x, new_y):\n",
    "        # new_y を Tensor に変換\n",
    "        if not isinstance(new_y, torch.Tensor):\n",
    "            new_y = torch.tensor([new_y], dtype=torch.double)\n",
    "        # 新しいデータポイントを追加\n",
    "        X_new = torch.cat([self.X, new_x.unsqueeze(0)], dim=0)\n",
    "        Y_new = torch.cat([self.Y, new_y])\n",
    "\n",
    "        self.X = X_new\n",
    "        self.Y = Y_new\n",
    "\n",
    "        # NumPy配列に変換\n",
    "        X_np = self.X.cpu().numpy()\n",
    "        Y_np = self.Y.cpu().numpy()\n",
    "\n",
    "        sensitivities = np.zeros(self.dim)\n",
    "        for i in range(self.dim):\n",
    "            sorted_indices = np.argsort(X_np[:, i])\n",
    "            sorted_x = X_np[sorted_indices, i]\n",
    "            sorted_y = Y_np[sorted_indices]\n",
    "            dx = np.diff(sorted_x)\n",
    "            dy = np.diff(sorted_y)\n",
    "            nonzero_dx = dx != 0\n",
    "            diffs = np.zeros_like(dx)\n",
    "            diffs[nonzero_dx] = dy[nonzero_dx] / dx[nonzero_dx]\n",
    "            sensitivities[i] = np.mean(np.abs(diffs))\n",
    "\n",
    "        total_sensitivity = np.sum(sensitivities) + 1e-10\n",
    "        new_sensitivity = sensitivities / total_sensitivity\n",
    "\n",
    "        # 指数移動平均で感度を更新\n",
    "        alpha = 0.1\n",
    "        self.dim_sensitivity = alpha * new_sensitivity + (1 - alpha) * self.dim_sensitivity\n",
    "\n",
    "    def update_bandit(self, selected_dims, y_new, y_pred):\n",
    "        # バンディットの更新\n",
    "        improvement = np.exp(-((y_pred - y_new) ** 2))\n",
    "        self.improvement_history.append(improvement)\n",
    "\n",
    "        self.total_pulls += 1\n",
    "        for dim in selected_dims:\n",
    "            self.arm_counts[dim] += 1\n",
    "            arm_contribution = improvement * self.dim_sensitivity[dim] / (\n",
    "                    sum(self.dim_sensitivity[selected_dims]) + 1e-10)\n",
    "            self.arm_rewards[dim] += arm_contribution\n",
    "\n",
    "\n",
    "    def optimize(self, n_iter):\n",
    "        # 最適化のメインループ\n",
    "        for _ in range(n_iter):\n",
    "            # 活性化する次元を選択\n",
    "            active_dims = self.select_active_dims()\n",
    "    \n",
    "            # モデルの学習データを準備\n",
    "            train_X = self.X[:, active_dims]\n",
    "            train_Y = self.Y.unsqueeze(-1)\n",
    "    \n",
    "            # ガウス過程モデルの作成とフィッティング\n",
    "            model = create_model(train_X, train_Y)\n",
    "            mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "            fit_gpytorch_model(mll)\n",
    "    \n",
    "            # Expected Improvement (EI) 獲得関数の定義\n",
    "            EI = ExpectedImprovement(model, best_f=self.best_f, maximize=False)\n",
    "            bounds_active = torch.stack([self.bounds[0][active_dims], self.bounds[1][active_dims]]).double()\n",
    "    \n",
    "            # 獲得関数の最適化\n",
    "            candidate, _ = optimize_acqf(\n",
    "                EI, bounds=bounds_active, q=1, num_restarts=10, raw_samples=100,\n",
    "                options={\"maxiter\": 200, \"batch_limit\": 5}\n",
    "            )\n",
    "    \n",
    "            # 新しい候補点を構築\n",
    "            x_new = torch.zeros(self.dim, dtype=torch.double)\n",
    "            x_new[active_dims] = candidate.squeeze()\n",
    "            x_new[np.setdiff1d(range(self.dim), active_dims)] = self.best_x[\n",
    "                np.setdiff1d(range(self.dim), active_dims)]\n",
    "    \n",
    "            # ガウス過程モデルによる予測値の計算\n",
    "            with torch.no_grad():\n",
    "                y_pred = model(x_new[active_dims].unsqueeze(0)).mean.item()\n",
    "    \n",
    "            # 目的関数の評価\n",
    "            y_new = self.obj_function(x_new.unsqueeze(0))\n",
    "            if isinstance(y_new, torch.Tensor):\n",
    "                y_new = y_new.item()\n",
    "    \n",
    "            # 感度の更新\n",
    "            self.calculate_dimension_sensitivity(x_new, y_new)\n",
    "    \n",
    "            # バンディットの更新\n",
    "            self.update_bandit(active_dims, y_new, y_pred)\n",
    "    \n",
    "            # 最良値の更新\n",
    "            if y_new < self.best_f:  # item() を取り除く\n",
    "                self.best_f = y_new\n",
    "                self.best_x = x_new\n",
    "    \n",
    "            # 評価履歴の更新\n",
    "            self.eval_history.append(self.best_f)\n",
    "    \n",
    "        # 次元選択の履歴をDataFrameに変換\n",
    "        self.arm_selection_df = pd.DataFrame(self.arm_selection_history,\n",
    "                                             columns=[f'Arm_{i}' for i in range(self.dim)])\n",
    "        self.arm_selection_df.index.name = 'Iteration'\n",
    "    \n",
    "        return self.best_x, self.best_f\n",
    "\n",
    "\n",
    "    # 結果の保存と可視化\n",
    "    def save_arm_selection_history(self, filename):\n",
    "        self.arm_selection_df.to_csv(filename)\n",
    "\n",
    "\n",
    "    def plot_dim_sensitivity(self):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.bar(range(self.dim), self.dim_sensitivity)\n",
    "        plt.xlabel('Dimension')\n",
    "        plt.ylabel('Sensitivity')\n",
    "        plt.title('Dimension Sensitivity')\n",
    "        plt.xticks(range(self.dim))\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ],
   "outputs": [],
   "execution_count": 529
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8sX27BRBGUy"
   },
   "source": [
    "# 最適化の実行\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KlrVSaIvBJMm",
    "ExecuteTime": {
     "end_time": "2024-09-24T20:43:26.360336Z",
     "start_time": "2024-09-24T20:43:26.357361Z"
    }
   },
   "source": [
    "dim = 10\n",
    "active_dim = 2\n",
    "bounds = torch.tensor([[-5.0] * dim, [5.0] * dim])\n",
    "n_initial = 200\n",
    "n_iter = 1000"
   ],
   "outputs": [],
   "execution_count": 530
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bFmsaVIdBMyY",
    "ExecuteTime": {
     "end_time": "2024-09-24T20:43:26.364322Z",
     "start_time": "2024-09-24T20:43:26.360336Z"
    }
   },
   "source": [
    "dropout_bo_mix = DropoutMixBO(dim, active_dim, bounds, n_initial, styblinski_tang, dropout_prob=0.1)\n",
    "dropout_bo_copy = DropoutMixBO(dim, active_dim, bounds, n_initial, styblinski_tang, dropout_prob=0.0)\n",
    "dropout_bo_random = DropoutMixBO(dim, active_dim, bounds, n_initial, styblinski_tang, dropout_prob=1.0)\n",
    "dropout_bandit_bc = DropoutMixBO_BC(dim, active_dim, bounds, n_initial, styblinski_tang, dropout_prob=0.0)\n",
    "dropout_bandit_est1 = DropoutMixEST1BO(dim, active_dim, bounds, n_initial, styblinski_tang, dropout_prob=0.0)\n",
    "basic_bo = BasicBO(dim, bounds, n_initial, styblinski_tang)\n",
    "rembo = REMBO(dim, active_dim, bounds, n_initial, styblinski_tang)"
   ],
   "outputs": [],
   "execution_count": 531
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HbTD7Vr8BaU1",
    "outputId": "79b7b8af-12e7-4f18-8e72-b7c53c8da3fe",
    "ExecuteTime": {
     "end_time": "2024-09-25T14:47:21.272266Z",
     "start_time": "2024-09-24T20:43:26.365327Z"
    }
   },
   "source": [
    "try:\n",
    "  with tqdm.notebook.tqdm(total=100, bar_format=TQDM_BAR_FORMAT) as pbar:\n",
    "    with io.capture_output() as captured:\n",
    "      dropout_mix_best_x , dropout_mix_best_f = dropout_bo_mix.optimize(n_iter)\n",
    "      pbar.update(20)\n",
    "      dropout_copy_best_x , dropout_copy_best_f = dropout_bo_copy.optimize(n_iter)\n",
    "      pbar.update(20)\n",
    "      dropout_random_best_x , dropout_random_best_f = dropout_bo_random.optimize(n_iter)\n",
    "      pbar.update(10)\n",
    "      rembo_best_x, rembo_best_f = rembo.optimize(n_iter)\n",
    "      pbar.update(10)\n",
    "      dropout_bandit_est1_best_x, dropout_bandit_est1_best_f = dropout_bandit_est1.optimize(n_iter)\n",
    "      pbar.update(20) \n",
    "      basic_bo_best_x, basic_bo_best_f = basic_bo.optimize(n_iter)\n",
    "      pbar.update(10)\n",
    "      dropout_bandit_bc_ucb_best_x, dropout_bandit_bc_ucb_best_f = dropout_bandit_bc.optimize(n_iter)\n",
    "      dropout_bandit_bc.save_arm_selection_history('dropout_bandit_bc_ucb_arm_selection_binary.csv')\n",
    "      pbar.update(10)\n",
    "    \n",
    "except subprocess.CalledProcessError:\n",
    "  print(captured)\n",
    "  raise"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/100 [elapsed: 00:00 remaining: ?]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "75321723850043d3ac841c5f6c240761"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[532], line 12\u001B[0m\n\u001B[0;32m     10\u001B[0m rembo_best_x, rembo_best_f \u001B[38;5;241m=\u001B[39m rembo\u001B[38;5;241m.\u001B[39moptimize(n_iter)\n\u001B[0;32m     11\u001B[0m pbar\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;241m10\u001B[39m)\n\u001B[1;32m---> 12\u001B[0m dropout_bandit_est1_best_x, dropout_bandit_est1_best_f \u001B[38;5;241m=\u001B[39m \u001B[43mdropout_bandit_est1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_iter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     13\u001B[0m pbar\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;241m20\u001B[39m) \n\u001B[0;32m     14\u001B[0m basic_bo_best_x, basic_bo_best_f \u001B[38;5;241m=\u001B[39m basic_bo\u001B[38;5;241m.\u001B[39moptimize(n_iter)\n",
      "Cell \u001B[1;32mIn[526], line 189\u001B[0m, in \u001B[0;36mDropoutMixEST1BO.optimize\u001B[1;34m(self, n_iter)\u001B[0m\n\u001B[0;32m    185\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miteration \u001B[38;5;241m<\u001B[39m n_iter:\n\u001B[0;32m    186\u001B[0m     \u001B[38;5;66;03m# CSARアルゴリズムの実行\u001B[39;00m\n\u001B[0;32m    187\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mremaining_dims) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccepted_dims) \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mactive_dim:\n\u001B[0;32m    188\u001B[0m         \u001B[38;5;66;03m# 推定アルゴリズムEST1を使用して報酬を推定\u001B[39;00m\n\u001B[1;32m--> 189\u001B[0m         theta_hat_t \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mEST1\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mremaining_dims\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mactive_dim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mepsilon_t\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdelta_t\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    190\u001B[0m         \u001B[38;5;66;03m# 推定報酬に基づいて次元をソート\u001B[39;00m\n\u001B[0;32m    191\u001B[0m         sorted_indices \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margsort(\u001B[38;5;241m-\u001B[39mtheta_hat_t)\n",
      "Cell \u001B[1;32mIn[526], line 78\u001B[0m, in \u001B[0;36mDropoutMixEST1BO.EST1\u001B[1;34m(self, N_t, k, epsilon_t, delta_t)\u001B[0m\n\u001B[0;32m     76\u001B[0m \u001B[38;5;66;03m# 負の次元の報酬をサンプリング\u001B[39;00m\n\u001B[0;32m     77\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(neg_dims) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m---> 78\u001B[0m     neg_sample \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_without_x\u001B[49m\u001B[43m(\u001B[49m\u001B[43mneg_dims\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     79\u001B[0m     neg_samples\u001B[38;5;241m.\u001B[39mappend(neg_sample)\n\u001B[0;32m     80\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     81\u001B[0m     \u001B[38;5;66;03m# neg_dims が空の場合、デフォルト値を使用（例として0を使用）\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[526], line 134\u001B[0m, in \u001B[0;36mDropoutMixEST1BO.predict_without_x\u001B[1;34m(self, active_dims)\u001B[0m\n\u001B[0;32m    132\u001B[0m model \u001B[38;5;241m=\u001B[39m create_model(train_X, train_Y)\n\u001B[0;32m    133\u001B[0m mll \u001B[38;5;241m=\u001B[39m ExactMarginalLogLikelihood(model\u001B[38;5;241m.\u001B[39mlikelihood, model)\n\u001B[1;32m--> 134\u001B[0m \u001B[43mfit_gpytorch_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmll\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    135\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n\u001B[0;32m    136\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miteration \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\botorch\\fit.py:164\u001B[0m, in \u001B[0;36mfit_gpytorch_model\u001B[1;34m(mll, optimizer, optimizer_kwargs, exclude, max_retries, **kwargs)\u001B[0m\n\u001B[0;32m    158\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m (\n\u001B[0;32m    159\u001B[0m     nullcontext()\n\u001B[0;32m    160\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m exclude \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    161\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m requires_grad_ctx(mll, assignments\u001B[38;5;241m=\u001B[39m{name: \u001B[38;5;28;01mFalse\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m exclude})\n\u001B[0;32m    162\u001B[0m ):\n\u001B[0;32m    163\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 164\u001B[0m         mll \u001B[38;5;241m=\u001B[39m \u001B[43mfit_gpytorch_mll\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    165\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmll\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    166\u001B[0m \u001B[43m            \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    167\u001B[0m \u001B[43m            \u001B[49m\u001B[43moptimizer_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    168\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    169\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    170\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m ModelFittingError \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m    171\u001B[0m         warn(\u001B[38;5;28mstr\u001B[39m(err), \u001B[38;5;167;01mRuntimeWarning\u001B[39;00m)\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\botorch\\fit.py:105\u001B[0m, in \u001B[0;36mfit_gpytorch_mll\u001B[1;34m(mll, closure, optimizer, closure_kwargs, optimizer_kwargs, **kwargs)\u001B[0m\n\u001B[0;32m    102\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m optimizer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:  \u001B[38;5;66;03m# defer to per-method defaults\u001B[39;00m\n\u001B[0;32m    103\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moptimizer\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m optimizer\n\u001B[1;32m--> 105\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mFitGPyTorchMLL\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    106\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmll\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    107\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmll\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlikelihood\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    108\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmll\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    109\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclosure\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclosure\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    110\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclosure_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclosure_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    111\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimizer_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    112\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    113\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\botorch\\utils\\dispatcher.py:93\u001B[0m, in \u001B[0;36mDispatcher.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     91\u001B[0m func \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__getitem__\u001B[39m(types\u001B[38;5;241m=\u001B[39mtypes)\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 93\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m MDNotImplementedError:\n\u001B[0;32m     95\u001B[0m     \u001B[38;5;66;03m# Traverses registered methods in order, yields whenever a match is found\u001B[39;00m\n\u001B[0;32m     96\u001B[0m     funcs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_iter(\u001B[38;5;241m*\u001B[39mtypes)\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\botorch\\fit.py:252\u001B[0m, in \u001B[0;36m_fit_fallback\u001B[1;34m(mll, _, __, closure, optimizer, closure_kwargs, optimizer_kwargs, max_attempts, warning_handler, caught_exception_types, **ignore)\u001B[0m\n\u001B[0;32m    250\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m catch_warnings(record\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m warning_list, debug(\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m    251\u001B[0m     simplefilter(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124malways\u001B[39m\u001B[38;5;124m\"\u001B[39m, category\u001B[38;5;241m=\u001B[39mOptimizationWarning)\n\u001B[1;32m--> 252\u001B[0m     \u001B[43moptimizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmll\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclosure\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclosure\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43moptimizer_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    254\u001B[0m \u001B[38;5;66;03m# Resolved warnings and determine whether or not to retry\u001B[39;00m\n\u001B[0;32m    255\u001B[0m done \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\botorch\\optim\\fit.py:120\u001B[0m, in \u001B[0;36mfit_gpytorch_mll_scipy\u001B[1;34m(mll, parameters, bounds, closure, closure_kwargs, method, options, callback, timeout_sec)\u001B[0m\n\u001B[0;32m    117\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m closure_kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    118\u001B[0m     closure \u001B[38;5;241m=\u001B[39m partial(closure, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mclosure_kwargs)\n\u001B[1;32m--> 120\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mscipy_minimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    121\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclosure\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclosure\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    122\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    123\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    124\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    125\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    126\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    127\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout_sec\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_sec\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    128\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    129\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m!=\u001B[39m OptimizationStatus\u001B[38;5;241m.\u001B[39mSUCCESS:\n\u001B[0;32m    130\u001B[0m     warn(\n\u001B[0;32m    131\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`scipy_minimize` terminated with status \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;241m.\u001B[39mstatus\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, displaying\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    132\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m original message from `scipy.optimize.minimize`: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;241m.\u001B[39mmessage\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    133\u001B[0m         OptimizationWarning,\n\u001B[0;32m    134\u001B[0m     )\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\botorch\\optim\\core.py:109\u001B[0m, in \u001B[0;36mscipy_minimize\u001B[1;34m(closure, parameters, bounds, callback, x0, method, options, timeout_sec)\u001B[0m\n\u001B[0;32m    101\u001B[0m         result \u001B[38;5;241m=\u001B[39m OptimizationResult(\n\u001B[0;32m    102\u001B[0m             step\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mnext\u001B[39m(call_counter),\n\u001B[0;32m    103\u001B[0m             fval\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mfloat\u001B[39m(wrapped_closure(x)[\u001B[38;5;241m0\u001B[39m]),\n\u001B[0;32m    104\u001B[0m             status\u001B[38;5;241m=\u001B[39mOptimizationStatus\u001B[38;5;241m.\u001B[39mRUNNING,\n\u001B[0;32m    105\u001B[0m             runtime\u001B[38;5;241m=\u001B[39mmonotonic() \u001B[38;5;241m-\u001B[39m start_time,\n\u001B[0;32m    106\u001B[0m         )\n\u001B[0;32m    107\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m callback(parameters, result)  \u001B[38;5;66;03m# pyre-ignore [29]\u001B[39;00m\n\u001B[1;32m--> 109\u001B[0m raw \u001B[38;5;241m=\u001B[39m \u001B[43mminimize_with_timeout\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    110\u001B[0m \u001B[43m    \u001B[49m\u001B[43mwrapped_closure\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    111\u001B[0m \u001B[43m    \u001B[49m\u001B[43mwrapped_closure\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstate\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx0\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx0\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp_float64\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    112\u001B[0m \u001B[43m    \u001B[49m\u001B[43mjac\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    113\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbounds_np\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    114\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    115\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    116\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwrapped_callback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    117\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout_sec\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_sec\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    118\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    120\u001B[0m \u001B[38;5;66;03m# Post-processing and outcome handling\u001B[39;00m\n\u001B[0;32m    121\u001B[0m wrapped_closure\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m=\u001B[39m asarray(raw\u001B[38;5;241m.\u001B[39mx)  \u001B[38;5;66;03m# set parameter state to optimal values\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\botorch\\optim\\utils\\timeout.py:80\u001B[0m, in \u001B[0;36mminimize_with_timeout\u001B[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options, timeout_sec)\u001B[0m\n\u001B[0;32m     77\u001B[0m     wrapped_callback \u001B[38;5;241m=\u001B[39m callback\n\u001B[0;32m     79\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 80\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43moptimize\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mminimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     81\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfun\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfun\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     82\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx0\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx0\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     83\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     84\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     85\u001B[0m \u001B[43m        \u001B[49m\u001B[43mjac\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mjac\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     86\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhess\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhess\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     87\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhessp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhessp\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     88\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     89\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconstraints\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconstraints\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     90\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtol\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     91\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwrapped_callback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     92\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     93\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m OptimizationTimeoutError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     95\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOptimization timed out after \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;241m.\u001B[39mruntime\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m seconds.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:731\u001B[0m, in \u001B[0;36mminimize\u001B[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001B[0m\n\u001B[0;32m    728\u001B[0m     res \u001B[38;5;241m=\u001B[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001B[0;32m    729\u001B[0m                              \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n\u001B[0;32m    730\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m meth \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124ml-bfgs-b\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m--> 731\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43m_minimize_lbfgsb\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfun\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjac\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    732\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    733\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m meth \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtnc\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    734\u001B[0m     res \u001B[38;5;241m=\u001B[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001B[38;5;241m=\u001B[39mcallback,\n\u001B[0;32m    735\u001B[0m                         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:407\u001B[0m, in \u001B[0;36m_minimize_lbfgsb\u001B[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001B[0m\n\u001B[0;32m    401\u001B[0m task_str \u001B[38;5;241m=\u001B[39m task\u001B[38;5;241m.\u001B[39mtobytes()\n\u001B[0;32m    402\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m task_str\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFG\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m    403\u001B[0m     \u001B[38;5;66;03m# The minimization routine wants f and g at the current x.\u001B[39;00m\n\u001B[0;32m    404\u001B[0m     \u001B[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001B[39;00m\n\u001B[0;32m    405\u001B[0m     \u001B[38;5;66;03m# until the completion of the current minimization iteration.\u001B[39;00m\n\u001B[0;32m    406\u001B[0m     \u001B[38;5;66;03m# Overwrite f and g:\u001B[39;00m\n\u001B[1;32m--> 407\u001B[0m     f, g \u001B[38;5;241m=\u001B[39m \u001B[43mfunc_and_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    408\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m task_str\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNEW_X\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m    409\u001B[0m     \u001B[38;5;66;03m# new iteration\u001B[39;00m\n\u001B[0;32m    410\u001B[0m     n_iterations \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:343\u001B[0m, in \u001B[0;36mScalarFunction.fun_and_grad\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    341\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray_equal(x, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx):\n\u001B[0;32m    342\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_x(x)\n\u001B[1;32m--> 343\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_update_fun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    344\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_grad()\n\u001B[0;32m    345\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mg\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:294\u001B[0m, in \u001B[0;36mScalarFunction._update_fun\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    292\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_update_fun\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    293\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_updated:\n\u001B[1;32m--> 294\u001B[0m         fx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_wrapped_fun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    295\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m fx \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lowest_f:\n\u001B[0;32m    296\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lowest_x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:20\u001B[0m, in \u001B[0;36m_wrapper_fun.<locals>.wrapped\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m     16\u001B[0m ncalls[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m# Send a copy because the user may overwrite it.\u001B[39;00m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m# Overwriting results in undefined behaviour because\u001B[39;00m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001B[39;00m\n\u001B[1;32m---> 20\u001B[0m fx \u001B[38;5;241m=\u001B[39m \u001B[43mfun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m# Make sure the function returns a true scalar\u001B[39;00m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39misscalar(fx):\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:79\u001B[0m, in \u001B[0;36mMemoizeJac.__call__\u001B[1;34m(self, x, *args)\u001B[0m\n\u001B[0;32m     77\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, \u001B[38;5;241m*\u001B[39margs):\n\u001B[0;32m     78\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\" returns the function value \"\"\"\u001B[39;00m\n\u001B[1;32m---> 79\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compute_if_needed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     80\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_value\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:73\u001B[0m, in \u001B[0;36mMemoizeJac._compute_if_needed\u001B[1;34m(self, x, *args)\u001B[0m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39mall(x \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mjac \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(x)\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m---> 73\u001B[0m     fg \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     74\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mjac \u001B[38;5;241m=\u001B[39m fg[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m     75\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_value \u001B[38;5;241m=\u001B[39m fg[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\botorch\\optim\\closures\\core.py:150\u001B[0m, in \u001B[0;36mNdarrayOptimizationClosure.__call__\u001B[1;34m(self, state, **kwargs)\u001B[0m\n\u001B[0;32m    147\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m=\u001B[39m state\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m     value_tensor, grad_tensors \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclosure\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    151\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mas_array(value_tensor)\n\u001B[0;32m    152\u001B[0m     grads \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_gradient_ndarray(fill_value\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfill_value)\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\botorch\\optim\\closures\\core.py:66\u001B[0m, in \u001B[0;36mForwardBackwardClosure.__call__\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m     64\u001B[0m values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     65\u001B[0m value \u001B[38;5;241m=\u001B[39m values \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreducer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreducer(values)\n\u001B[1;32m---> 66\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     68\u001B[0m grads \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(param\u001B[38;5;241m.\u001B[39mgrad \u001B[38;5;28;01mfor\u001B[39;00m param \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparameters\u001B[38;5;241m.\u001B[39mvalues())\n\u001B[0;32m     69\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback:\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\torch\\_tensor.py:525\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    515\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    517\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    518\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    523\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    524\u001B[0m     )\n\u001B[1;32m--> 525\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    526\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    527\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    262\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    264\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    265\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    266\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 267\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    272\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    273\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    274\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    275\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\baysian_optimization\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    742\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    743\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 744\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    745\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[0;32m    746\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    747\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    748\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 532
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## アームの履歴 BC_UCBのバンディット"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T14:47:21.273270Z",
     "start_time": "2024-09-25T14:47:21.273270Z"
    }
   },
   "source": [
    "# Load the saved CSV file\n",
    "df = pd.read_csv(\"dropout_bandit_bc_ucb_arm_selection_binary.csv\", index_col=\"Iteration\")\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Calculate arm selection frequency\n",
    "arm_freq = df.sum().sort_values(ascending=False)\n",
    "\n",
    "# Create a bar plot of arm selection frequency\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=arm_freq.index, y=arm_freq.values)\n",
    "plt.title(\"Arm Selection Frequency (BC-UCB)\")\n",
    "plt.xlabel(\"Arm\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create a heatmap of arm selection over iterations\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df.T, cmap=\"YlOrRd\", cbar_kws={'label': 'Selected'})\n",
    "plt.title(\"Arm Selection Over Iterations (BC-UCB)\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Arm\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout_Banditのimprovementのプロット"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(dropout_bandit_bc.improvement_history)), dropout_bandit_bc.improvement_history, label='Dropout-Bandit-BC-UCB')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Improvement')\n",
    "plt.title('Improvement vs Iteration')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout_Banditの次元重要度のプロット"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "dropout_bandit_bc.plot_dim_sensitivity()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b046tAbcBxyU"
   },
   "source": [
    "# 結果のプロット"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "id": "4nCY_jN2BveQ",
    "outputId": "4ec6730f-0ad0-4e71-a860-3cc0e3205a28"
   },
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(range(1, n_initial + n_iter + 1), dropout_bo_mix.eval_history, label='Dropout-Mix BO')\n",
    "plt.plot(range(1, n_initial + n_iter + 1), dropout_bo_copy.eval_history, label='Dropout-Copy BO')\n",
    "plt.plot(range(1, n_initial + n_iter + 1), dropout_bo_random.eval_history, label='Dropout-Random BO')\n",
    "plt.plot(range(1, n_initial + n_iter + 1), rembo.eval_history, label='REMBO')\n",
    "plt.plot(range(1, n_initial + n_iter + 1), dropout_bandit_bc.eval_history, label='Dropout-Bandit-BC-UCB BO')\n",
    "plt.plot(range(1, n_initial + n_iter + 1), basic_bo.eval_history, label='Basic BO')\n",
    "plt.plot(range(1, n_initial + n_iter + 1), dropout_bandit_est1.eval_history, label='Dropout-Bandit-EST1 BO')\n",
    "plt.axhline(y=global_optimum, color='r', linestyle='--', label='Global Optimum')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Best Function Value')\n",
    "plt.title('Comparison of Optimization Algorithms　for Rosenbrock Function')\n",
    "plt.legend()\n",
    "plt.yscale('symlog')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0af17b96dece47eca9ca9d7be6dc63b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1afa0f53e6f740aa844484642c3d80c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1b55749b3fa043b8a6fd555305db2944",
       "IPY_MODEL_70740e89fa304143b3e7b3a4a0cd87ad",
       "IPY_MODEL_e63abcaacc6449039d73b58d7296265e"
      ],
      "layout": "IPY_MODEL_496ad9319d8243d280de82a7b1076962"
     }
    },
    "1b55749b3fa043b8a6fd555305db2944": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_84a211d6ea5a49e4861bbe0d4bc48a8b",
      "placeholder": "​",
      "style": "IPY_MODEL_b6bf801aeaff419ea299d38dcfdd4897",
      "value": "100%"
     }
    },
    "496ad9319d8243d280de82a7b1076962": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4bdb725ab6284f468a9d718aa13bd69d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "70740e89fa304143b3e7b3a4a0cd87ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0af17b96dece47eca9ca9d7be6dc63b0",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a51f753d216a4f548c43c058db765d34",
      "value": 100
     }
    },
    "72625ba6d5ac46f8b6efea358be8cf59": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84a211d6ea5a49e4861bbe0d4bc48a8b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a51f753d216a4f548c43c058db765d34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b6bf801aeaff419ea299d38dcfdd4897": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e63abcaacc6449039d73b58d7296265e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_72625ba6d5ac46f8b6efea358be8cf59",
      "placeholder": "​",
      "style": "IPY_MODEL_4bdb725ab6284f468a9d718aa13bd69d",
      "value": " 100/100 [elapsed: 00:45 remaining: 00:00]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
